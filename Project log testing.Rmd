```{r}
library(tidyverse)
library(tidymodels)
library(caret)
library(gridExtra)
library(ranger)
library(vip)
library(skimr)
library(ggplot2)
library(GGally)
library(ggcorrplot)
library(ROCR)
library(mice)
library(rpart) #for classification trees
library(rpart.plot) #for plotting trees
```



```{r}
#Read in Data
test = read_csv("/Users/gregwolcott/Documents/UNCW/BAN 502 - Predictive Analytics/Course Project/product-failure-kaggle-competition-s24/test.csv")
train = read_csv("/Users/gregwolcott/Documents/UNCW/BAN 502 - Predictive Analytics/Course Project/product-failure-kaggle-competition-s24/train.csv")

```

```{r}
str(train)
summary(train)
head(train)
```

```{r}
#Convert data to factors
train = train %>% select(-id,-attribute_0,-attribute_2,-attribute_1,-attribute_3,-product_code)
train = train %>% mutate(failure = as_factor(failure))

```

```{r}
summary(train)
```

```{r}
set.seed(12345) #sets seed for random number generator
imp_final = mice(train, m=5, method='pmm', printFlag=FALSE)
train = complete(imp_final) 

#Look at cleaned up data
summary(train)
```


```{r}

#LOOK AT MEASUREMENT CORRELATIONS
#loading
ggplot(train) + geom_boxplot(aes(x = factor(failure), y = loading))

#Measurement0
ggplot(train) + geom_boxplot(aes(x = factor(failure), y = measurement_0))

#Measurement1
ggplot(train) + geom_boxplot(aes(x = factor(failure), y = measurement_1))

#Measurement2
ggplot(train) + geom_boxplot(aes(x = factor(failure), y = measurement_2))

#Measurement3
ggplot(train) + geom_boxplot(aes(x = factor(failure), y = measurement_3))

#Measurement4
ggplot(train) + geom_boxplot(aes(x = factor(failure), y = measurement_4))

#Measurement5
ggplot(train) + geom_boxplot(aes(x = factor(failure), y = measurement_5))

#Measurement6
ggplot(train) + geom_boxplot(aes(x = factor(failure), y = measurement_6))

#Measurement7
ggplot(train) + geom_boxplot(aes(x = factor(failure), y = measurement_7))

#Measurement8
ggplot(train) + geom_boxplot(aes(x = factor(failure), y = measurement_8))

#Measurement9
ggplot(train) + geom_boxplot(aes(x = factor(failure), y = measurement_9))

#Measurement10
ggplot(train) + geom_boxplot(aes(x = factor(failure), y = measurement_10))

#Measurement11
ggplot(train) + geom_boxplot(aes(x = factor(failure), y = measurement_11))

#Measurement12
ggplot(train) + geom_boxplot(aes(x = factor(failure), y = measurement_12))

#Measurement13
ggplot(train) + geom_boxplot(aes(x = factor(failure), y = measurement_13))

#Measurement14
ggplot(train) + geom_boxplot(aes(x = factor(failure), y = measurement_14))

#Measurement15
ggplot(train) + geom_boxplot(aes(x = factor(failure), y = measurement_15))

#Measurement16
ggplot(train) + geom_boxplot(aes(x = factor(failure), y = measurement_16))

#Measurement17
ggplot(train) + geom_boxplot(aes(x = factor(failure), y = measurement_17))
```





```{r}

#1st attempt only relevant variables
train_model = 
  logistic_reg() %>% #note the use of logistic_reg
  set_engine("glm") #standard logistic regression engine is glm
train_model1_recipe = recipe(failure ~ loading+measurement_2+measurement_4+measurement_17+measurement_0, train) %>% 
  step_dummy(all_nominal(), -all_outcomes()) 

logreg_wf_test = workflow() %>%
  add_recipe(train_model1_recipe) %>% 
  add_model(train_model)

train_model1_fit = fit(logreg_wf_test, train)
```


```{r}
summary(train_model1_fit$fit$fit$fit)

```


```{r}

predictions = predict(train_model1_fit, train, type="prob")[2]

ROCRpred = prediction(predictions, train$failure) 

###You shouldn't need to ever change the next two lines:
ROCRperf = performance(ROCRpred, "tpr", "fpr")
plot(ROCRperf, colorize=TRUE, print.cutoffs.at=seq(0,1,by=0.1), text.adj=c(-0.2,1.7))

as.numeric(performance(ROCRpred, "auc")@y.values)

opt.cut = function(perf, pred){
  cut.ind = mapply(FUN=function(x, y, p){
    d = (x - 0)^2 + (y-1)^2
    ind = which(d == min(d))
    c(sensitivity = y[[ind]], specificity = 1-x[[ind]], 
      cutoff = p[[ind]])
  }, perf@x.values, perf@y.values, pred@cutoffs)
}
print(opt.cut(ROCRperf, ROCRpred))
```

```{r}
t1 = table(train$failure,predictions > 0.2088707)
(t1[1,1]+t1[2,2])/nrow(train)
t1
```







#classification tree
training_recipe = recipe(failure ~ loading, train)

tree_model = decision_tree() %>% 
  set_engine("rpart", model = TRUE) %>% #don't forget the model = TRUE flag
  set_mode("classification")

training_wflow = 
  workflow() %>% 
  add_model(tree_model) %>% 
  add_recipe(training_recipe)

training_fit = fit(training_wflow, train)

training_fit %>%
  pull_workflow_fit() %>%
  pluck("fit")  

tree = training_fit %>% 
  pull_workflow_fit() %>% 
  pluck("fit")

rpart.plot(tree)
training_fit$fit$fit$fit$cptable